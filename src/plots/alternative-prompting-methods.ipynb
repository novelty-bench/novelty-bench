{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yimingz3/src/second-best-bench\n"
     ]
    }
   ],
   "source": [
    "%cd ~/src/second-best-bench/\n",
    "from src.plots.common import models, model_order\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dfs = []\n",
    "\n",
    "for subset in [\"curated\"]:\n",
    "    for model_family, model_path, model_alias in models:\n",
    "        if model_family in [\"Anthropic\", \"OpenAI\"]:\n",
    "            df = pd.read_json(f\"eval/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"Resampling\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "            df = pd.read_json(f\"eval-ic/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"In-context regeneration\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "            df = pd.read_json(f\"eval-paraphrase/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"Paraphrasing\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "            df = pd.read_json(f\"eval-system-prompt/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"System prompt\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "df = pd.read_json(f\"eval-human/scores.jsonl\", lines=True)\n",
    "df[\"subset\"] = subset\n",
    "df[\"model_family\"] = \"Human\"\n",
    "df[\"model_alias\"] = \"Human\"\n",
    "df[\"sampling_method\"] = \"Human\"\n",
    "score_dfs.append(df)\n",
    "\n",
    "\n",
    "model_scores = pd.concat(score_dfs)\n",
    "model_scores[\"distinct\"] = model_scores[\"partition_scores\"].map(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary(df):\n",
    "    \n",
    "    summary = df.groupby(['model_family', 'model_alias', 'sampling_method']).agg(\n",
    "        mean_distinct=('distinct', 'mean'),\n",
    "        mean_utility=('utility', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary['distinct'] = summary['mean_distinct'] + 1\n",
    "    \n",
    "    return summary[['model_family', 'model_alias', 'distinct', 'mean_utility', 'sampling_method']]\n",
    "\n",
    "eval_data = compute_summary(model_scores)\n",
    "eval_data = eval_data.rename(columns={'mean_utility': 'utility'})\n",
    "\n",
    "eval_data = eval_data[eval_data[\"model_family\"].isin([\"OpenAI\", \"Anthropic\", \"Human\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bee8c938775c4ababfbf754aadffd415.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bee8c938775c4ababfbf754aadffd415.vega-embed details,\n",
       "  #altair-viz-bee8c938775c4ababfbf754aadffd415.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bee8c938775c4ababfbf754aadffd415\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bee8c938775c4ababfbf754aadffd415\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bee8c938775c4ababfbf754aadffd415\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"data\": {\"name\": \"data-05fa37561582a330fd042b57365f925b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"In-context-regeneration\", \"Paraphrasing\", \"System prompt\", \"Human\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \"GPT-4o Mini\", \"GPT-4o\", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"Command R7B\", \"Command R\", \"Command R+\", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"Human\", \"Paraphrasing\", \"System prompt\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"utility\", \"title\": \"Utility\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-05fa37561582a330fd042b57365f925b\": [{\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 8.370000000000001, \"utility\": 4.289650716658814, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 5.67, \"utility\": 3.8299814570274866, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 3.74, \"utility\": 3.4661860682439656, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 4.7, \"utility\": 3.7844730298063016, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 8.23, \"utility\": 5.129323783771319, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 5.54, \"utility\": 3.670889431733147, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 3.56, \"utility\": 3.196910364964106, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 4.48, \"utility\": 3.275471119870956, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 9.11, \"utility\": 5.619754697948813, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 5.78, \"utility\": 3.8364399408561316, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 3.35, \"utility\": 3.01948637549244, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 4.83, \"utility\": 3.3211626331342177, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Human\", \"model_alias\": \"Human\", \"distinct\": 7.58, \"utility\": 4.729710540805749, \"sampling_method\": \"Human\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 8.809999999999999, \"utility\": 5.160768729188054, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.05, \"utility\": 4.3611758394383235, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.89, \"utility\": 3.5737638712366993, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.44, \"utility\": 4.058899028788297, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 9.11, \"utility\": 4.542004556817336, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 5.82, \"utility\": 3.836212913337988, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 3.92, \"utility\": 3.431915119440076, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 5.25, \"utility\": 3.1001714834917182, \"sampling_method\": \"System prompt\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base chart for grouping\n",
    "utility_grouped = alt.Chart(eval_data).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order),\n",
    "    y=alt.Y('utility:Q', title='Utility'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\", \"In-context-regeneration\", \"Paraphrasing\", \"System prompt\", \"Human\"]),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\", \"Human\", \"Paraphrasing\", \"System prompt\"])  # This creates the grouping within each model\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "utility_grouped.save(\"plots/alternative-prompting-utility.json\")\n",
    "utility_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-541e68bf300f4030877293d9b0291c74.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-541e68bf300f4030877293d9b0291c74.vega-embed details,\n",
       "  #altair-viz-541e68bf300f4030877293d9b0291c74.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-541e68bf300f4030877293d9b0291c74\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-541e68bf300f4030877293d9b0291c74\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-541e68bf300f4030877293d9b0291c74\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"data\": {\"name\": \"data-05fa37561582a330fd042b57365f925b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"In-context-regeneration\", \"Paraphrasing\", \"System prompt\", \"Human\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \"GPT-4o Mini\", \"GPT-4o\", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"Command R7B\", \"Command R\", \"Command R+\", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"Human\", \"Paraphrasing\", \"System prompt\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"distinct\", \"title\": \"Distinct generations (out of 10)\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-05fa37561582a330fd042b57365f925b\": [{\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 8.370000000000001, \"utility\": 4.289650716658814, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 5.67, \"utility\": 3.8299814570274866, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 3.74, \"utility\": 3.4661860682439656, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 4.7, \"utility\": 3.7844730298063016, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 8.23, \"utility\": 5.129323783771319, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 5.54, \"utility\": 3.670889431733147, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 3.56, \"utility\": 3.196910364964106, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Haiku\", \"distinct\": 4.48, \"utility\": 3.275471119870956, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 9.11, \"utility\": 5.619754697948813, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 5.78, \"utility\": 3.8364399408561316, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 3.35, \"utility\": 3.01948637549244, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3.5 Sonnet\", \"distinct\": 4.83, \"utility\": 3.3211626331342177, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Human\", \"model_alias\": \"Human\", \"distinct\": 7.58, \"utility\": 4.729710540805749, \"sampling_method\": \"Human\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 8.809999999999999, \"utility\": 5.160768729188054, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.05, \"utility\": 4.3611758394383235, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.89, \"utility\": 3.5737638712366993, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.44, \"utility\": 4.058899028788297, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 9.11, \"utility\": 4.542004556817336, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 5.82, \"utility\": 3.836212913337988, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 3.92, \"utility\": 3.431915119440076, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 5.25, \"utility\": 3.1001714834917182, \"sampling_method\": \"System prompt\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base chart for grouping\n",
    "distinct_grouped = alt.Chart(eval_data).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order),\n",
    "        y=alt.Y('distinct:Q', title='Distinct generations (out of 10)'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\", \"In-context-regeneration\", \"Paraphrasing\", \"System prompt\", \"Human\"]),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\", \"Human\", \"Paraphrasing\", \"System prompt\"])  # This creates the grouping within each model    \n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "distinct_grouped.save(\"plots/alternative-prompting-distinct.json\")\n",
    "distinct_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "second-best-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
