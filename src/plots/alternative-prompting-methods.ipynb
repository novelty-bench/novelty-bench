{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yimingz3/src/second-best-bench\n"
     ]
    }
   ],
   "source": [
    "%cd ~/src/second-best-bench/\n",
    "from src.plots.common import models, model_order\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dfs = []\n",
    "\n",
    "for subset in [\"curated\"]:\n",
    "    for model_family, model_path, model_alias in models:\n",
    "        df = pd.read_json(f\"eval/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "        df[\"subset\"] = subset\n",
    "        df[\"model_family\"] = model_family\n",
    "        df[\"model_alias\"] = model_alias\n",
    "        df[\"sampling_method\"] = \"Resampling\"\n",
    "\n",
    "        score_dfs.append(df)\n",
    "\n",
    "    \n",
    "    for model_family, model_path, model_alias in models:\n",
    "        df = pd.read_json(f\"eval-ic/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "        df[\"subset\"] = subset\n",
    "        df[\"model_family\"] = model_family\n",
    "        df[\"model_alias\"] = model_alias\n",
    "        df[\"sampling_method\"] = \"In-context regeneration\"\n",
    "\n",
    "        score_dfs.append(df)\n",
    "\n",
    "model_scores = pd.concat(score_dfs)\n",
    "model_scores[\"distinct\"] = model_scores[\"partition_scores\"].map(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary(df):\n",
    "    \n",
    "    summary = df.groupby(['model_family', 'model_alias', 'sampling_method']).agg(\n",
    "        mean_distinct=('distinct', 'mean'),\n",
    "        mean_utility=('utility', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary['distinct'] = summary['mean_distinct'] + 1\n",
    "    \n",
    "    return summary[['model_family', 'model_alias', 'distinct', 'mean_utility', 'sampling_method']]\n",
    "\n",
    "eval_data = compute_summary(model_scores)\n",
    "eval_data = eval_data.rename(columns={'mean_utility': 'utility'})\n",
    "\n",
    "eval_data = eval_data[eval_data[\"model_family\"].isin([\"OpenAI\", \"Gemini\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4c52d5fd742c4e90979555674e74fd9a.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4c52d5fd742c4e90979555674e74fd9a.vega-embed details,\n",
       "  #altair-viz-4c52d5fd742c4e90979555674e74fd9a.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4c52d5fd742c4e90979555674e74fd9a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4c52d5fd742c4e90979555674e74fd9a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4c52d5fd742c4e90979555674e74fd9a\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"data\": {\"name\": \"data-3ecd505cb4a7b3fb63c212ad128c808b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \"GPT-4o Mini\", \"GPT-4o\", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"Command R7B\", \"Command R\", \"Command R+\", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"utility\", \"title\": \"Utility\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-3ecd505cb4a7b3fb63c212ad128c808b\": [{\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 1.5 Pro\", \"distinct\": 6.86, \"utility\": 41.80631372956604, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 1.5 Pro\", \"distinct\": 3.07, \"utility\": 24.557160875199852, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash\", \"distinct\": 7.89, \"utility\": 37.114724871914795, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash\", \"distinct\": 4.15, \"utility\": 29.565255720141067, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash Lite\", \"distinct\": 7.85, \"utility\": 36.8570292802071, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash Lite\", \"distinct\": 4.29, \"utility\": 30.348658667629376, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 8.2, \"utility\": 34.83384870613897, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 3.6, \"utility\": 23.945447018824833, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.89, \"utility\": 31.896097736745542, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.15, \"utility\": 22.811212498633424, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 6.39, \"utility\": 25.044539224225996, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 3.12, \"utility\": 20.242669173937188, \"sampling_method\": \"Resampling\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base chart for grouping\n",
    "utility_grouped = alt.Chart(eval_data).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order),\n",
    "    y=alt.Y('utility:Q', title='Utility'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\"]),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\"])  # This creates the grouping within each model\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "utility_grouped.save(\"plots/alternative-prompting-utility.json\")\n",
    "utility_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-36da048df34641058d921ba06f33693b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-36da048df34641058d921ba06f33693b.vega-embed details,\n",
       "  #altair-viz-36da048df34641058d921ba06f33693b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-36da048df34641058d921ba06f33693b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-36da048df34641058d921ba06f33693b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-36da048df34641058d921ba06f33693b\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"data\": {\"name\": \"data-3ecd505cb4a7b3fb63c212ad128c808b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \"GPT-4o Mini\", \"GPT-4o\", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"Command R7B\", \"Command R\", \"Command R+\", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"distinct\", \"title\": \"Distinct generations (out of 10)\", \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-3ecd505cb4a7b3fb63c212ad128c808b\": [{\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 1.5 Pro\", \"distinct\": 6.86, \"utility\": 41.80631372956604, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 1.5 Pro\", \"distinct\": 3.07, \"utility\": 24.557160875199852, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash\", \"distinct\": 7.89, \"utility\": 37.114724871914795, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash\", \"distinct\": 4.15, \"utility\": 29.565255720141067, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash Lite\", \"distinct\": 7.85, \"utility\": 36.8570292802071, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Flash Lite\", \"distinct\": 4.29, \"utility\": 30.348658667629376, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 8.2, \"utility\": 34.83384870613897, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 3.6, \"utility\": 23.945447018824833, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 6.89, \"utility\": 31.896097736745542, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.15, \"utility\": 22.811212498633424, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 6.39, \"utility\": 25.044539224225996, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o Mini\", \"distinct\": 3.12, \"utility\": 20.242669173937188, \"sampling_method\": \"Resampling\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base chart for grouping\n",
    "distinct_grouped = alt.Chart(eval_data).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order),\n",
    "        y=alt.Y('distinct:Q', title='Distinct generations (out of 10)'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\"]),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\"]),\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "distinct_grouped.save(\"plots/alternative-prompting-distinct.json\")\n",
    "distinct_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "second-best-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
