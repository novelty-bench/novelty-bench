{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yimingz3/src/second-best-bench\n"
     ]
    }
   ],
   "source": [
    "%cd ~/src/second-best-bench/\n",
    "from src.plots.common import models, model_order\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, generation_count=8):\n",
    "    row[\"partition\"] = row[\"partition\"][:generation_count]\n",
    "    row[\"distinct\"] = max(row[\"partition\"]) + 1\n",
    "    row[\"generation_scores\"] = row[\"generation_scores\"][:generation_count]\n",
    "    row[\"utility\"] = np.average(row[\"generation_scores\"], weights=0.8 ** np.arange(generation_count))\n",
    "    row[\"partition_scores\"] = row[\"partition_scores\"][:row[\"distinct\"]]\n",
    "    return row\n",
    "\n",
    "\n",
    "score_dfs = []\n",
    "\n",
    "for subset in [\"curated\"]:\n",
    "    for model_family, model_path, model_alias in models:\n",
    "        if model_path in [\"anthropic/claude-3-opus@20240229\", \"openai/gpt-4o-2024-11-20\", \"gemini/gemini-2.0-pro-exp-02-05\"]:\n",
    "            df = pd.read_json(f\"eval/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"Resampling\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "            df = pd.read_json(f\"eval-ic/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"In-context regeneration\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "            df = pd.read_json(f\"eval-paraphrase/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"Paraphrasing\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "            df = pd.read_json(f\"eval-system-prompt/{subset}/{model_path}/scores.jsonl\", lines=True)\n",
    "            df[\"subset\"] = subset\n",
    "            df[\"model_family\"] = model_family\n",
    "            df[\"model_alias\"] = model_alias\n",
    "            df[\"sampling_method\"] = \"System prompt\"\n",
    "            score_dfs.append(df)\n",
    "\n",
    "\n",
    "df = pd.read_json(f\"eval-human/scores.jsonl\", lines=True)\n",
    "df[\"subset\"] = subset\n",
    "df[\"model_family\"] = \"Human\"\n",
    "df[\"model_alias\"] = \"Human\"\n",
    "df[\"sampling_method\"] = \"Human\"\n",
    "score_dfs.append(df)\n",
    "\n",
    "\n",
    "model_scores = pd.concat(score_dfs)\n",
    "model_scores = model_scores.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>generations</th>\n",
       "      <th>partition</th>\n",
       "      <th>distinct</th>\n",
       "      <th>generation_scores</th>\n",
       "      <th>partition_scores</th>\n",
       "      <th>utility</th>\n",
       "      <th>subset</th>\n",
       "      <th>model_family</th>\n",
       "      <th>model_alias</th>\n",
       "      <th>sampling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curated-17</td>\n",
       "      <td>What is the top item you would add to a grocer...</td>\n",
       "      <td>human</td>\n",
       "      <td>[Durian, Onions, Ice Cream, Hot sauce, Fresh f...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 0, 5, 6]</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 1, 2, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[1, 1, 2, 1, 1, 1, 1]</td>\n",
       "      <td>1.075056</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curated-45</td>\n",
       "      <td>What is the main reason people don't get hired...</td>\n",
       "      <td>human</td>\n",
       "      <td>[Their resume got filtered out by AI, They don...</td>\n",
       "      <td>[0, 1, 0, 2, 3, 4, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 1, 0, 6, 1, 1, 0, 0]</td>\n",
       "      <td>[1, 1, 6, 1, 1]</td>\n",
       "      <td>1.348015</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>curated-77</td>\n",
       "      <td>Name a star other than the Sun.</td>\n",
       "      <td>human</td>\n",
       "      <td>[Antares, Neptune, Orion , Rho Cassiopeiae, Ca...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 6]</td>\n",
       "      <td>7</td>\n",
       "      <td>[10, 1, 1, 9, 1, 9, 10, 0]</td>\n",
       "      <td>[10, 1, 1, 9, 1, 9, 10]</td>\n",
       "      <td>5.293781</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>curated-3</td>\n",
       "      <td>Write a haiku about a whale and a walnut tree.</td>\n",
       "      <td>human</td>\n",
       "      <td>[Vast life overflows -\\nWhale's mighty form, t...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>[9, 2, 7, 10, 9, 8, 2, 6]</td>\n",
       "      <td>[9, 2, 7, 10, 9, 8, 2, 6]</td>\n",
       "      <td>6.798720</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>curated-46</td>\n",
       "      <td>What's a saying that English teachers hate?</td>\n",
       "      <td>human</td>\n",
       "      <td>[Grammar doesn't matter, I don't care, I didn'...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 1, 1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>[2, 1, 1, 1, 8, 0, 0, 0]</td>\n",
       "      <td>[2, 1, 1, 1, 8]</td>\n",
       "      <td>1.737217</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>curated-75</td>\n",
       "      <td>Name one person who was involved in the Americ...</td>\n",
       "      <td>human</td>\n",
       "      <td>[Alexander Hamilton, George Washington, George...</td>\n",
       "      <td>[0, 1, 1, 2, 3, 4, 1, 5]</td>\n",
       "      <td>6</td>\n",
       "      <td>[10, 10, 0, 6, 7, 9, 0, 9]</td>\n",
       "      <td>[10, 10, 6, 7, 9, 9]</td>\n",
       "      <td>6.915355</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>curated-15</td>\n",
       "      <td>What would you invent to make the world a more...</td>\n",
       "      <td>human</td>\n",
       "      <td>[Flying vehicles , flying cars, Teleportation ...</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>7</td>\n",
       "      <td>[2, 0, 2, 1, 1, 2, 1, 1]</td>\n",
       "      <td>[2, 2, 1, 1, 2, 1, 1]</td>\n",
       "      <td>1.280615</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>curated-44</td>\n",
       "      <td>What is the first thing to check when your car...</td>\n",
       "      <td>human</td>\n",
       "      <td>[Battery, the Engine, Fuel Levels , If the bat...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 0, 5, 0]</td>\n",
       "      <td>6</td>\n",
       "      <td>[10, 1, 2, 7, 7, 0, 1, 0]</td>\n",
       "      <td>[10, 1, 2, 7, 7, 1]</td>\n",
       "      <td>4.516394</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>curated-16</td>\n",
       "      <td>One thing you might find in a magical forest.</td>\n",
       "      <td>human</td>\n",
       "      <td>[Flowers that can talk, Unicorn, Talking Tree,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>[8, 9, 9, 2, 2, 10, 1, 1]</td>\n",
       "      <td>[8, 9, 9, 2, 2, 10, 1, 1]</td>\n",
       "      <td>6.380911</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>curated-76</td>\n",
       "      <td>Name one style of combat sports.</td>\n",
       "      <td>human</td>\n",
       "      <td>[Brazilian Jiu-Jitsu, Wrestling, Boxing , Kend...</td>\n",
       "      <td>[0, 1, 2, 3, 0, 4, 3, 5]</td>\n",
       "      <td>6</td>\n",
       "      <td>[10, 10, 10, 9, 0, 2, 0, 10]</td>\n",
       "      <td>[10, 10, 10, 9, 2, 10]</td>\n",
       "      <td>7.632648</td>\n",
       "      <td>curated</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             prompt  model  \\\n",
       "0   curated-17  What is the top item you would add to a grocer...  human   \n",
       "1   curated-45  What is the main reason people don't get hired...  human   \n",
       "2   curated-77                    Name a star other than the Sun.  human   \n",
       "3    curated-3     Write a haiku about a whale and a walnut tree.  human   \n",
       "4   curated-46        What's a saying that English teachers hate?  human   \n",
       "..         ...                                                ...    ...   \n",
       "95  curated-75  Name one person who was involved in the Americ...  human   \n",
       "96  curated-15  What would you invent to make the world a more...  human   \n",
       "97  curated-44  What is the first thing to check when your car...  human   \n",
       "98  curated-16      One thing you might find in a magical forest.  human   \n",
       "99  curated-76                   Name one style of combat sports.  human   \n",
       "\n",
       "                                          generations  \\\n",
       "0   [Durian, Onions, Ice Cream, Hot sauce, Fresh f...   \n",
       "1   [Their resume got filtered out by AI, They don...   \n",
       "2   [Antares, Neptune, Orion , Rho Cassiopeiae, Ca...   \n",
       "3   [Vast life overflows -\\nWhale's mighty form, t...   \n",
       "4   [Grammar doesn't matter, I don't care, I didn'...   \n",
       "..                                                ...   \n",
       "95  [Alexander Hamilton, George Washington, George...   \n",
       "96  [Flying vehicles , flying cars, Teleportation ...   \n",
       "97  [Battery, the Engine, Fuel Levels , If the bat...   \n",
       "98  [Flowers that can talk, Unicorn, Talking Tree,...   \n",
       "99  [Brazilian Jiu-Jitsu, Wrestling, Boxing , Kend...   \n",
       "\n",
       "                   partition  distinct             generation_scores  \\\n",
       "0   [0, 1, 2, 3, 4, 0, 5, 6]         7      [1, 1, 2, 1, 1, 0, 1, 1]   \n",
       "1   [0, 1, 0, 2, 3, 4, 0, 0]         5      [1, 1, 0, 6, 1, 1, 0, 0]   \n",
       "2   [0, 1, 2, 3, 4, 5, 6, 6]         7    [10, 1, 1, 9, 1, 9, 10, 0]   \n",
       "3   [0, 1, 2, 3, 4, 5, 6, 7]         8     [9, 2, 7, 10, 9, 8, 2, 6]   \n",
       "4   [0, 1, 2, 3, 4, 1, 1, 1]         5      [2, 1, 1, 1, 8, 0, 0, 0]   \n",
       "..                       ...       ...                           ...   \n",
       "95  [0, 1, 1, 2, 3, 4, 1, 5]         6    [10, 10, 0, 6, 7, 9, 0, 9]   \n",
       "96  [0, 0, 1, 2, 3, 4, 5, 6]         7      [2, 0, 2, 1, 1, 2, 1, 1]   \n",
       "97  [0, 1, 2, 3, 4, 0, 5, 0]         6     [10, 1, 2, 7, 7, 0, 1, 0]   \n",
       "98  [0, 1, 2, 3, 4, 5, 6, 7]         8     [8, 9, 9, 2, 2, 10, 1, 1]   \n",
       "99  [0, 1, 2, 3, 0, 4, 3, 5]         6  [10, 10, 10, 9, 0, 2, 0, 10]   \n",
       "\n",
       "             partition_scores   utility   subset model_family model_alias  \\\n",
       "0       [1, 1, 2, 1, 1, 1, 1]  1.075056  curated        Human       Human   \n",
       "1             [1, 1, 6, 1, 1]  1.348015  curated        Human       Human   \n",
       "2     [10, 1, 1, 9, 1, 9, 10]  5.293781  curated        Human       Human   \n",
       "3   [9, 2, 7, 10, 9, 8, 2, 6]  6.798720  curated        Human       Human   \n",
       "4             [2, 1, 1, 1, 8]  1.737217  curated        Human       Human   \n",
       "..                        ...       ...      ...          ...         ...   \n",
       "95       [10, 10, 6, 7, 9, 9]  6.915355  curated        Human       Human   \n",
       "96      [2, 2, 1, 1, 2, 1, 1]  1.280615  curated        Human       Human   \n",
       "97        [10, 1, 2, 7, 7, 1]  4.516394  curated        Human       Human   \n",
       "98  [8, 9, 9, 2, 2, 10, 1, 1]  6.380911  curated        Human       Human   \n",
       "99     [10, 10, 10, 9, 2, 10]  7.632648  curated        Human       Human   \n",
       "\n",
       "   sampling_method  \n",
       "0            Human  \n",
       "1            Human  \n",
       "2            Human  \n",
       "3            Human  \n",
       "4            Human  \n",
       "..             ...  \n",
       "95           Human  \n",
       "96           Human  \n",
       "97           Human  \n",
       "98           Human  \n",
       "99           Human  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores[model_scores[\"model_family\"] == \"Human\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary(df):\n",
    "    \n",
    "    summary = df.groupby(['model_family', 'model_alias', 'sampling_method']).agg(\n",
    "        mean_distinct=('distinct', 'mean'),\n",
    "        mean_utility=('utility', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary['distinct'] = summary['mean_distinct'] + 1\n",
    "    \n",
    "    return summary[['model_family', 'model_alias', 'distinct', 'mean_utility', 'sampling_method']]\n",
    "\n",
    "eval_data = compute_summary(model_scores)\n",
    "eval_data = eval_data.rename(columns={'mean_utility': 'utility'})\n",
    "\n",
    "eval_data = eval_data[eval_data[\"model_family\"].isin([\"OpenAI\", \"Anthropic\", \"Gemini\", \"Human\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4e34efc321a8439f879a769f2307ff4c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4e34efc321a8439f879a769f2307ff4c.vega-embed details,\n",
       "  #altair-viz-4e34efc321a8439f879a769f2307ff4c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4e34efc321a8439f879a769f2307ff4c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4e34efc321a8439f879a769f2307ff4c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4e34efc321a8439f879a769f2307ff4c\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"layer\": [{\"data\": {\"name\": \"data-afcc91cb4811635964ae1269017e177d\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \" \", \"Command R7B\", \"Command R\", \"Command R+\", \"  \", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"   \", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"    \", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\", \"     \", \"GPT-4o Mini\", \"GPT-4o\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"utility\", \"title\": \"Utility\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-9a4e944092b68fd881b45809eb734a76\"}, \"mark\": {\"type\": \"rule\", \"color\": \"black\", \"size\": 2, \"strokeDash\": [6, 4]}, \"encoding\": {\"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"height\": 200, \"width\": 260, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-afcc91cb4811635964ae1269017e177d\": [{\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 7.18, \"utility\": 4.463157504560289, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 5.1, \"utility\": 3.983110932698431, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 3.51, \"utility\": 3.6528272565359026, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 4.24, \"utility\": 3.9366382744417683, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 7.87, \"utility\": 5.9168677808230985, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 5.44, \"utility\": 4.679118149183762, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 3.17, \"utility\": 3.165670908581957, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 5.55, \"utility\": 4.958371276788818, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 7.45, \"utility\": 5.337824072792374, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 5.29, \"utility\": 4.485443094045015, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.6, \"utility\": 3.748617455527563, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 5.66, \"utility\": 4.175904936801922, \"sampling_method\": \"System prompt\"}], \"data-9a4e944092b68fd881b45809eb734a76\": [{\"y\": 4.729710540805749}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Create a base chart for grouping\n",
    "utility_grouped = alt.Chart(eval_data[eval_data[\"model_family\"] != \"Human\"]).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order, axis=alt.Axis(labelAngle=-0)),\n",
    "    y=alt.Y('utility:Q', title='Utility'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"]),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"])  # This creates the grouping within each model\n",
    ").properties(\n",
    "    width=260,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# Get human utility value\n",
    "human_utility = eval_data[eval_data[\"model_family\"] == \"Human\"][\"utility\"].values[0]\n",
    "\n",
    "# Create a horizontal rule for human performance\n",
    "human_rule = alt.Chart(pd.DataFrame({'y': [human_utility]})).mark_rule(\n",
    "    strokeDash=[6, 4],\n",
    "    size=2,\n",
    "    color='black'\n",
    ").encode(\n",
    "    y='y:Q'\n",
    ")\n",
    "\n",
    "# Add text label for human performance\n",
    "human_text = alt.Chart(pd.DataFrame({'y': [human_utility], 'text': ['Human']})).mark_text(\n",
    "    align='left',\n",
    "    baseline='bottom',\n",
    "    dx=-90,\n",
    "    dy=-5,\n",
    "    fontSize=10\n",
    ").encode(\n",
    "    y='y:Q',\n",
    "    text='text:N'\n",
    ")\n",
    "\n",
    "# Combine the charts\n",
    "final_chart = utility_grouped + human_rule\n",
    "\n",
    "final_chart.save(\"plots/alternative-prompting-utility.json\")\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1aa1179273cb456d8d82268b8e8af0f2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1aa1179273cb456d8d82268b8e8af0f2.vega-embed details,\n",
       "  #altair-viz-1aa1179273cb456d8d82268b8e8af0f2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1aa1179273cb456d8d82268b8e8af0f2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1aa1179273cb456d8d82268b8e8af0f2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1aa1179273cb456d8d82268b8e8af0f2\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"title\": {\"font\": \"TeX Gyre Pagella\"}, \"axis\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"header\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"legend\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\"}, \"text\": {\"labelFont\": \"TeX Gyre Pagella\", \"titleFont\": \"TeX Gyre Pagella\", \"font\": \"TeX Gyre Pagella\"}}, \"layer\": [{\"data\": {\"name\": \"data-afcc91cb4811635964ae1269017e177d\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"sampling_method\", \"legend\": null, \"sort\": [\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"], \"title\": \"Sampling method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_alias\", \"sort\": [\"Claude 3.5 Haiku\", \"Claude 3.5 Sonnet\", \"Claude 3 Opus\", \" \", \"Command R7B\", \"Command R\", \"Command R+\", \"  \", \"Gemini 1.5 Pro\", \"Gemini 2.0 Flash Lite\", \"Gemini 2.0 Flash\", \"Gemini 2.0 Pro\", \"   \", \"Gemma 2 2B\", \"Gemma 2 9B\", \"Gemma 2 27B\", \"    \", \"Llama 3.2 1B\", \"Llama 3.2 3B\", \"Llama 3.1 8B\", \"Llama 3.3 70B\", \"Llama 3.1 405B\", \"     \", \"GPT-4o Mini\", \"GPT-4o\"], \"title\": \"\", \"type\": \"nominal\"}, \"xOffset\": {\"field\": \"sampling_method\", \"sort\": [\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"distinct\", \"title\": \"Distinct generations\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-24c25fd2665b1436ece0aa51e588da87\"}, \"mark\": {\"type\": \"rule\", \"color\": \"black\", \"size\": 2, \"strokeDash\": [6, 4]}, \"encoding\": {\"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"height\": 200, \"width\": 260, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-afcc91cb4811635964ae1269017e177d\": [{\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 7.18, \"utility\": 4.463157504560289, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 5.1, \"utility\": 3.983110932698431, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 3.51, \"utility\": 3.6528272565359026, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Anthropic\", \"model_alias\": \"Claude 3 Opus\", \"distinct\": 4.24, \"utility\": 3.9366382744417683, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 7.87, \"utility\": 5.9168677808230985, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 5.44, \"utility\": 4.679118149183762, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 3.17, \"utility\": 3.165670908581957, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"Gemini\", \"model_alias\": \"Gemini 2.0 Pro\", \"distinct\": 5.55, \"utility\": 4.958371276788818, \"sampling_method\": \"System prompt\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 7.45, \"utility\": 5.337824072792374, \"sampling_method\": \"In-context regeneration\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 5.29, \"utility\": 4.485443094045015, \"sampling_method\": \"Paraphrasing\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 3.6, \"utility\": 3.748617455527563, \"sampling_method\": \"Resampling\"}, {\"model_family\": \"OpenAI\", \"model_alias\": \"GPT-4o\", \"distinct\": 5.66, \"utility\": 4.175904936801922, \"sampling_method\": \"System prompt\"}], \"data-24c25fd2665b1436ece0aa51e588da87\": [{\"y\": 7.58}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base chart for grouping\n",
    "distinct_grouped = alt.Chart(eval_data[eval_data[\"model_family\"] != \"Human\"]).mark_bar().encode(\n",
    "    x=alt.X('model_alias:N', title='', sort=model_order, axis=alt.Axis(labelAngle=-0)),\n",
    "    y=alt.Y('distinct:Q', title='Distinct generations'),\n",
    "    color=alt.Color('sampling_method:N', title='Sampling method', sort=[\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"], legend=None),\n",
    "    xOffset=alt.XOffset('sampling_method:N', sort=[\"Resampling\", \"In-context regeneration\", \"Paraphrasing\", \"System prompt\"])  # This creates the grouping within each model    \n",
    ").properties(\n",
    "    width=260,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# Get human distinct value\n",
    "human_distinct = eval_data[eval_data[\"model_family\"] == \"Human\"][\"distinct\"].values[0]\n",
    "\n",
    "# Create a horizontal rule for human performance\n",
    "human_rule = alt.Chart(pd.DataFrame({'y': [human_distinct]})).mark_rule(\n",
    "    strokeDash=[6, 4],\n",
    "    size=2,\n",
    "    color='black'\n",
    ").encode(\n",
    "    y='y:Q'\n",
    ")\n",
    "\n",
    "# Add text label for human performance\n",
    "human_text = alt.Chart(pd.DataFrame({'y': [human_utility], 'text': ['Human']})).mark_text(\n",
    "    align='left',\n",
    "    baseline='bottom',\n",
    "    dx=-90,\n",
    "    dy=-75,\n",
    "    fontSize=10\n",
    ").encode(\n",
    "    y='y:Q',\n",
    "    text='text:N'\n",
    ")\n",
    "\n",
    "# Combine the charts\n",
    "final_distinct_chart = distinct_grouped + human_rule\n",
    "\n",
    "final_distinct_chart.save(\"plots/alternative-prompting-distinct.json\")\n",
    "final_distinct_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "second-best-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
